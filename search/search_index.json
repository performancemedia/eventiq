{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Eventiq","text":""},{"location":"#welcome-to-eventiq-documentation","title":"Welcome to eventiq documentation","text":"<p>Cloud native, event driven microservice framework for python</p> <p>Note: This package is under active development and is not recommended for production usage</p> <p>Version: 0.2.4</p> <p>Documentation: https://performancemedia.github.io/eventiq/</p> <p>Repository: https://github.com/performancemedia/eventiq</p>"},{"location":"#about","title":"About","text":"<p>The package utilizes <code>anyio</code> and <code>pydantic</code> as the only required dependencies. For messages Cloud Events format is used. Service can be run as standalone processes, or included into starlette (e.g. FastAPI) applications.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install eventiq\n</code></pre>"},{"location":"#multiple-brokers-support","title":"Multiple brokers support","text":"<ul> <li>Stub (in memory using <code>asyncio.Queue</code> for PoC, local development and testing)</li> <li>NATS (with JetStream)</li> <li>Redis Pub/Sub</li> <li>Kafka</li> <li>Rabbitmq</li> <li>Google Cloud PubSub</li> <li>And more coming...</li> </ul>"},{"location":"#optional-dependencies","title":"Optional Dependencies","text":"<ul> <li><code>cli</code> - <code>typer</code></li> <li>broker of choice: <code>nats</code>, <code>kafka</code>, <code>rabbitmq</code>, <code>redis</code>, <code>pubsub</code></li> <li>custom message serializers: <code>msgpack</code>, <code>orjson</code></li> <li><code>prometheus</code> - Metric exposure via <code>PrometheusMiddleware</code></li> <li><code>opentelemetry</code> - Tracing support</li> </ul>"},{"location":"#motivation","title":"Motivation","text":"<p>Python has many \"worker-queue\" libraries and frameworks, such as:</p> <ul> <li>Celery</li> <li>Dramatiq</li> <li>Huey</li> <li>arq</li> </ul> <p>However, those libraries don't provide a pub/sub pattern, useful for creating event driven and loosely coupled systems. Furthermore, the majority of those libraries do not support <code>asyncio</code>. This is why this project was born.</p>"},{"location":"#basic-usage","title":"Basic usage","text":"<pre><code>import asyncio\nfrom eventiq import Service, CloudEvent, Middleware\nfrom eventiq.backends.nats.broker import JetStreamBroker\n\n\nclass SendMessageMiddleware(Middleware):\n    async def after_broker_connect(self, broker: \"Broker\") -&gt; None:\n        print(f\"After service start, running with {broker}\")\n        await asyncio.sleep(10)\n        for i in range(100):\n            await broker.publish(\"test.topic\", data={\"counter\": i})\n        print(\"Published event(s)\")\n\nbroker = JetStreamBroker(url=\"nats://localhost:4222\")\nbroker.add_middleware(SendMessageMiddleware())\n\nservice = Service(name=\"example-service\", broker=broker)\n\n@service.subscribe(\"test.topic\")\nasync def example_run(message: CloudEvent):\n    print(f\"Received Message {message.id} with data: {message.data}\")\n\n\nif __name__ == \"__main__\":\n    service.run()\n</code></pre>"},{"location":"#scaling","title":"Scaling","text":"<p>Each message is load-balanced (depending on broker) between all service instances with the same <code>name</code>. To scale number of processes you can use containers (docker/k8s), supervisor, or web server like gunicorn.</p>"},{"location":"async_api/","title":"AsyncAPI","text":""},{"location":"async_api/#documentation-generation","title":"Documentation generation","text":"<p>eventiq can automatically generate Async API documentation of your service.</p>"},{"location":"async_api/#usage","title":"Usage","text":"<p><pre><code>eventiq generate-docs {package}.{module}:{service-instance} --format=yaml|json --out=output-path\n</code></pre> Example: <pre><code>eventiq generate-docs examples.asyncapi:service --format=yaml --out=./asyncapi.yaml\n</code></pre></p> <p>Result</p> <pre><code>asyncapi: 2.5.0\nchannels:\n  test.topic:\n    publish:\n      message:\n        contentType: application/json\n        description: ''\n        messageId: example_service_myevent\n        payload:\n          $ref: '#/components/schemas/MyEvent'\n        tags: []\n    subscribe:\n      message:\n        contentType: application/json\n        description: Consumer for processing MyEvent(s)\n        messageId: example_run_myevent\n        payload:\n          $ref: '#/components/schemas/MyEvent'\n        tags: []\ncomponents:\n  schemas:\n    MyData:\n      description: Main data for service\n      properties:\n        counter:\n          title: Counter\n          type: integer\n        info:\n          title: Info\n          type: string\n      required:\n      - counter\n      - info\n      title: MyData\n      type: object\n    MyEvent:\n      description: Some custom event\n      properties:\n        data:\n          $ref: '#/components/schemas/MyData'\n        datacontenttype:\n          default: application/json\n          title: Datacontenttype\n          type: string\n        id:\n          title: Id\n          type: string\n        source:\n          title: Source\n          type: string\n        subject:\n          title: Subject\n          type: string\n        time:\n          format: date-time\n          title: Time\n          type: string\n        traceid:\n          title: Traceid\n          type: string\n        type:\n          default: MyEvent\n          title: Type\n          type: string\n        version:\n          default: '1.0'\n          title: Version\n          type: string\n      required:\n      - subject\n      - data\n      title: MyEvent\n      type: object\ndefaultContentType: application/json\ninfo:\n  title: Example-Service\n  version: '1.0'\nservers: {}\n</code></pre>"},{"location":"async_api/#preview","title":"Preview","text":""},{"location":"changelog/","title":"Version 1.0 Pre Release","text":"<p>New features:</p> <ul> <li>Multiple broker support within 1 service</li> <li>AsyncAPI v3.0.0 spec</li> <li>Pydantic V2</li> <li>Dataref Middleware</li> <li><code>watch</code> is now an option (<code>--reload</code>) to <code>run</code> command</li> <li>Cloudpickle encoder</li> <li>Error raising in middlewares support</li> <li><code>CloudEvent.context</code> propagation from <code>Service</code></li> <li>Runner now accepts <code>AbstractService</code></li> </ul>"},{"location":"consumers/","title":"Consumers","text":"<p>The framework allows to add consumers in two ways:</p> <ol> <li>Using decorator <code>Service.subscribe</code></li> </ol> <pre><code>from eventiq import Service, CloudEvent\n\nservice = Service(...) # options\n\n# all the options passed to subscribe, are used to initialize consumer class (__init__)\n@service.subscribe(\"example_topic\") \nasync def my_consumer(message: CloudEvent):\n    print(f\"Received message {message}\")\n</code></pre> <p>This will create <code>FnConsumer</code> instance under the hood. It's also possible to use regular functions (without <code>async</code>) which will be run in the thread pool.</p> <ol> <li>By subclassing <code>GenericConsumer</code></li> </ol> <p><pre><code>from eventiq import GenericConsumer, CloudEvent, Service\n\nservice = Service(...) # options\n\n@service.subscribe(\"example_topic\")\nclass MyConsumer(GenericConsumer[CloudEvent]):\n    name = \"my_consumer\"\n    x = 10\n\n    async def process(self, message: CloudEvent):\n        print(f\"Consumer {self.name}.{self.x} received message  {message}\")\n</code></pre> Subclassing <code>Consumer</code> allows you to specify the base class and/or use mixins with shared functionality.</p>"},{"location":"consumers/#automatic-response-forwarding","title":"Automatic response forwarding","text":"<p>If <code>ForwardResponse</code> option is set for consumer, then returned value is automatically published to the broker.</p>"},{"location":"features/","title":"Features","text":""},{"location":"features/#eventiq-features","title":"eventiq features","text":"<ul> <li>Modern, <code>asyncio</code> based python 3.8+ syntax</li> <li>Minimal dependencies, only <code>anyio</code> and <code>pydantic</code> are required</li> <li>Automatic message parsing based on type annotations (like FastAPI)</li> <li>Code hot-reload</li> <li>Highly scalable: each service can process hundreds of tasks concurrently,     all messages are load balanced between all instances by default</li> <li>Resilient - at least once delivery for all messages by default </li> <li>Customizable &amp; pluggable message encoders (json, msgpack, custom)</li> <li>Json formatted logger</li> <li>Multiple broker support (Nats, Kafka, Rabbitmq, Redis, PubSub, and more coming)</li> <li>Easily extensible via Middlewares and Plugins</li> <li>Cloud Events standard as base message structure (no more python specific <code>*args</code> and <code>**kwargs</code> in messages)</li> <li>AsyncAPI documentation generation from code</li> <li>Twelve factor app approach - stdout logging, configuration through environment variables</li> <li>Out-of-the-box integration with Prometheus (metrics) and OpenTelemetry (tracing)</li> <li>Application bootstrap via <code>.yaml</code> file (see examples/configuration)</li> </ul>"},{"location":"http/","title":"HTTP","text":""},{"location":"http/#integration-with-web-frameworks","title":"Integration with web frameworks","text":"<p>Unlike Nameko or Faust which try  to provide basic utilities for adding http/rest utilities to their framework using werkzeug or aiohttp, eventiq allows you to integrate <code>service</code> to an existing web app like FastAPI.</p>"},{"location":"http/#fastapi-example","title":"FastAPI Example","text":"<pre><code>from typing import Any\nfrom uuid import UUID\nfrom fastapi import FastAPI, Body\nfrom fastapi.responses import JSONResponse, Response\nfrom eventiq import Service, CloudEvent\nfrom eventiq.middlewares import HealthCheckMiddleware\nfrom eventiq.backends.nats import JetStreamBroker, JetStreamResultBackend\nfrom eventiq.contrib.fastapi import FastAPIServicePlugin\n\nbroker = JetStreamBroker(url=\"nats://localhost:4222\")\nkv = JetStreamResultBackend(broker)\n\nbroker.add_middleware(HealthCheckMiddleware())\n\nservice = Service(name=\"example-service\", broker=broker)\n\n\napp = FastAPI()\n\nFastAPIServicePlugin(service, app, healthcheck_url=\"/healthz\")\n\n\n@service.subscribe(\"events.topic\", name=\"test_consumer\", store_results=True)\nasync def handler(message: CloudEvent):\n    print(f\"Received Message {message.id} with data: {message.data}\")\n    return message.data\n\n\n@app.post(\"/publish\", status_code=202, response_model=CloudEvent)\nasync def publish_event(data: Any = Body(...)):\n    event = CloudEvent(topic=\"events.topic\", data=data)\n    await service.publish_event(event)\n    return event\n\n@app.get(\"/{message_id}\")\nasync def get_result(message_id: UUID):\n    res = await kv.get_result(service.name, message_id)\n    if res is None:\n        return Response(status_code=404, content=\"Key not found\")\n    return JSONResponse(content=res)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p><pre><code>pip install eventiq\n</code></pre> or</p> <pre><code>poetry add eventiq\n</code></pre>"},{"location":"installation/#installing-optional-dependencies","title":"Installing optional dependencies","text":"<pre><code>pip install 'eventiq[extension]'\n</code></pre>"},{"location":"installation/#available-extensions","title":"Available extensions","text":"<p>Misc:</p> <ul> <li><code>cli</code></li> <li><code>prometheus</code></li> <li><code>opentelemetry</code></li> </ul> <p>Brokers</p> <ul> <li><code>nats</code></li> <li><code>rabbitmq</code></li> <li><code>kafka</code></li> <li><code>pubsub</code></li> <li><code>redis</code></li> </ul> <p>Encoders:</p> <ul> <li><code>orjson</code></li> <li><code>ormsgpack</code></li> </ul>"},{"location":"installation/#installing-multiple-extensions","title":"Installing multiple extensions","text":"<pre><code>pip install 'eventiq[cli, orjson, nats]'\n</code></pre>"},{"location":"installation/#installing-commons-cli-orjson-prometheus-and-broker","title":"Installing commons (cli, orjson, prometheus) and broker","text":"<pre><code>pip install 'eventiq[common, nats]'\n</code></pre>"},{"location":"middlewares/","title":"Middlewares","text":""},{"location":"middlewares/#available-middlewares","title":"Available middlewares","text":"<ul> <li><code>DebugMiddleware</code> - Logging every middleware function</li> <li><code>ErrorHandlerMiddleware</code> - Custom error handling</li> <li><code>PrometheusMiddleware</code> - Prometheus exporter of message processing metrics</li> <li><code>HealthCheckMiddleware</code> - Broker connection healthcheck middleware</li> <li><code>RetryMiddleware</code> - Automatic message retries middleware</li> <li><code>OpenTelemetryMiddleware</code> - Integration with OpenTelemetry, automatic spans on publish and process</li> </ul>"},{"location":"middlewares/#writing-custom-middleware","title":"Writing custom middleware","text":"<ol> <li>Subclass from <code>eventiq.Middleware</code></li> <li>Implement any of the following methods</li> </ol>"},{"location":"middlewares/#eventiq.middleware.Middleware","title":"<code>eventiq.middleware.Middleware</code>","text":"<p>             Bases: <code>Generic[T]</code>, <code>LoggerMixin</code></p> <p>Base class for middlewares</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_ack","title":"<code>after_ack(broker: T, service: Service, consumer: Consumer, message: Message) -&gt; None</code>  <code>async</code>","text":"<p>Called after message is acknowledged</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_broker_connect","title":"<code>after_broker_connect(broker: T) -&gt; None</code>  <code>async</code>","text":"<p>Called after broker connects</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_broker_disconnect","title":"<code>after_broker_disconnect(broker: T) -&gt; None</code>  <code>async</code>","text":"<p>Called after broker disconnects</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_consumer_start","title":"<code>after_consumer_start(broker: T, service: Service, consumer: Consumer) -&gt; None</code>  <code>async</code>","text":"<p>Called after consumer is started</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_nack","title":"<code>after_nack(broker: T, service: Service, consumer: Consumer, message: Message) -&gt; None</code>  <code>async</code>","text":"<p>Called after message is rejected</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_process_message","title":"<code>after_process_message(broker: T, service: Service, consumer: Consumer, message: CloudEvent, result: Any | None = None, exc: Exception | None = None) -&gt; None</code>  <code>async</code>","text":"<p>Called after message is processed (but not acknowledged/rejected yet)</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_publish","title":"<code>after_publish(broker: T, message: CloudEvent, **kwargs) -&gt; None</code>  <code>async</code>","text":"<p>Called after message is published</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_service_start","title":"<code>after_service_start(broker: T, service: Service)</code>  <code>async</code>","text":"<p>Called after service starts</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_service_stop","title":"<code>after_service_stop(broker: T, service: Service)</code>  <code>async</code>","text":"<p>Called after service stops</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.after_skip_message","title":"<code>after_skip_message(broker: T, service: Service, consumer: Consumer, message: CloudEvent) -&gt; None</code>  <code>async</code>","text":"<p>Called after message is skipped by the middleware</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_ack","title":"<code>before_ack(broker: T, service: Service, consumer: Consumer, message: Message) -&gt; None</code>  <code>async</code>","text":"<p>Called before message is acknowledged</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_broker_connect","title":"<code>before_broker_connect(broker: T) -&gt; None</code>  <code>async</code>","text":"<p>Called before broker connects</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_broker_disconnect","title":"<code>before_broker_disconnect(broker: T) -&gt; None</code>  <code>async</code>","text":"<p>Called before broker disconnects</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_consumer_start","title":"<code>before_consumer_start(broker: T, service: Service, consumer: Consumer) -&gt; None</code>  <code>async</code>","text":"<p>Called before consumer is started</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_nack","title":"<code>before_nack(broker: T, service: Service, consumer: Consumer, message: Message) -&gt; None</code>  <code>async</code>","text":"<p>Called before message is rejected</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_process_message","title":"<code>before_process_message(broker: T, service: Service, consumer: Consumer, message: CloudEvent) -&gt; None</code>  <code>async</code>","text":"<p>Called before message is processed</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_publish","title":"<code>before_publish(broker: T, message: CloudEvent, **kwargs) -&gt; None</code>  <code>async</code>","text":"<p>Called before message is published</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_service_start","title":"<code>before_service_start(broker: T, service: Service)</code>  <code>async</code>","text":"<p>Called before service starts</p>"},{"location":"middlewares/#eventiq.middleware.Middleware.before_service_stop","title":"<code>before_service_stop(broker: T, service: Service)</code>  <code>async</code>","text":"<p>Called before service stops</p>"},{"location":"service/","title":"Service","text":""},{"location":"service/#eventiq.service.Service","title":"<code>eventiq.service.Service</code>","text":"<p>             Bases: <code>AbstractService</code>, <code>LoggerMixin</code></p> <p>Logical group of consumers. Provides group (queue) name and handles versioning</p>"},{"location":"service/#eventiq.service.Service.subscribe","title":"<code>subscribe(topic: str | None = None, *, name: str | None = None, brokers: tuple[str] = ('default'), timeout: Timeout | None = None, dynamic: bool = False, reply_to: ReplyTo | None = None, tags: Tags = None, retry_strategy: RetryStrategy | None = None, store_results: bool = False, encoder: Encoder | None = None, parameters: dict[str, Any] | None = None, **options: Any)</code>","text":""},{"location":"service/#service-runner","title":"Service Runner","text":"<p>Service runner class is a service container, responsible to run one or more services, as a standalone program. If you want to run only one service, the <code>ServiceRunner</code> instance will be created under the hood.</p>"},{"location":"service/#eventiq.runner.ServiceRunner","title":"<code>eventiq.runner.ServiceRunner</code>","text":"<p>             Bases: <code>LoggerMixin</code></p> <p>Service container for running multiple service instances in one process</p> <p>Parameters:</p> Name Type Description Default <code>services</code> <code>AbstractService</code> <p>Sequence of services to run</p> <code>()</code>"},{"location":"service/#eventiq.runner.ServiceRunner.__init__","title":"<code>__init__(*services: AbstractService, enable_signal_handler: bool = True) -&gt; None</code>","text":""},{"location":"service/#eventiq.runner.ServiceRunner.run","title":"<code>run() -&gt; None</code>  <code>async</code>","text":""},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom eventiq import Service, Middleware, CloudEvent\nfrom eventiq.backends.nats import JetStreamBroker\n\n\nbroker = JetStreamBroker(url=\"nats://localhost:4222\")\n\nservice = Service(name=\"example-service\", broker=broker)\n\n\nclass SendMessageMiddleware(Middleware):\n    async def after_service_start(self, broker: JetStreamBroker, service: Service):\n        print(f\"After service start, running with {broker}\")\n        await asyncio.sleep(10)\n        for i in range(100):\n            await service.publish(\"test.topic\", data={\"counter\": i})\n        print(\"Published event(s)\")\n\n\nbroker.add_middleware(SendMessageMiddleware())\n\n\n@service.subscribe(\"test.topic\")\nasync def example_run(message: CloudEvent):\n    print(f\"Received Message {message.id} with data: {message.data}\")\n</code></pre> <p>Run with</p> <pre><code>eventiq run app:service --log-level=info\n</code></pre>"},{"location":"usage/#watching-for-changes","title":"Watching for changes","text":"<pre><code>eventiq run app:service --log-level=info --reload=.\n</code></pre>"},{"location":"usage/#testing","title":"Testing","text":"<p><code>StubBroker</code> class is provided as in memory replacement for running unit tests</p> <pre><code>import os\n\n\ndef get_broker(**kwargs):\n    if os.getenv('ENV') == 'TEST':\n        from eventiq.backends.stub import StubBroker\n        return StubBroker()\n    else:\n        from eventiq.backends.rabbitmq import RabbitmqBroker\n        return RabbitmqBroker(**kwargs)\n\nbroker = get_broker()\n</code></pre> <p>Furthermore, subscribers are just regular python coroutines, so it's possible to test them simply by invocation</p> <pre><code># main.py\n@service.subscribe(...)\nasync def my_subscriber(message: CloudEvent):\n    return 42\n\n# tests.py\nfrom main import my_subscriber\n\nasync def test_my_subscriber():\n    result = await my_subscriber(None)\n    assert result == 42\n</code></pre>"},{"location":"usage/#configuration","title":"Configuration","text":"<p>Explicit is better than implicit.</p> <p>eventiq package does not provide any 'magic' configuration management or dependency injection providers. You have to create <code>broker</code>, <code>service</code>, and <code>middlewares</code> instances by hand and provide all the parameters. However, it's up to user which approach to use: config file (yaml/ini), pydantic settings management, constants in code, dependency injector library etc.</p>"},{"location":"usage/#cli","title":"CLI","text":"<p>Getting help: <pre><code>eventiq --help\n</code></pre></p> <p>Installing shell autocompletion: <pre><code>eventiq --install-completion [bash|zsh|fish|powershell|pwsh]\n</code></pre></p>"},{"location":"usage/#basic-commands","title":"Basic commands","text":"<ul> <li><code>run</code> - run service or group of services</li> <li><code>docs</code> - generate AsyncAPI docs</li> </ul>"},{"location":"examples/asyncapi/","title":"AsyncAPI","text":"examples/asyncapi.py<pre><code>import asyncio\n\nfrom pydantic import BaseModel\n\nfrom eventiq import CloudEvent, Middleware, Service\nfrom eventiq.asyncapi import PublishInfo\nfrom eventiq.backends.nats.broker import JetStreamBroker\n\nbroker = JetStreamBroker(url=\"nats://nats:password@localhost:4222\")\n\n\nclass MyData(BaseModel):\n    \"\"\"Main data for service\"\"\"\n\n    counter: int\n    info: str\n\n\n# @publishes(\"test.topic.{param}.*\")\nclass MyEvent(CloudEvent[MyData]):\n    \"\"\"Some custom event\"\"\"\n\n    @property\n    def param(self) -&gt; str:\n        return self.topic_split[2]\n\n\nclass MyCommand(CloudEvent[int], topic=\"commands.run\"):\n    \"\"\"Command representing current number of items\"\"\"\n\n\nservice = Service(\n    name=\"example-service\",\n    version=\"1.0\",\n    broker=broker,\n    publish_info=[\n        PublishInfo.s(\n            MyEvent,\n            topic=\"test.topic.{param}.*\",\n            tags=[\"tag2\"],\n            description=\"Publishes when X happens\",\n        )\n    ],\n    tags_metadata=[{\"name\": \"tag1\", \"description\": \"Some tag 1\"}],\n    context={\"db\": \"MY Database\"},\n)\n\n\nclass SendMessageMiddleware(Middleware):\n    async def after_service_start(self, broker, service: Service):\n        self.logger.info(f\"After service start, running with {broker}\")\n        await asyncio.sleep(5)\n        for i in range(100):\n            await broker.publish(\n                MyEvent(\n                    topic=\"test.topic\", data=MyData(**{\"counter\": i, \"info\": \"default\"})\n                )\n            )\n        self.logger.info(\"Published event(s)\")\n\n\nbroker.add_middleware(SendMessageMiddleware())\n\n\n@service.subscribe(\"test.topic.{param}.*\", tags=[\"tag1\"])\nasync def example_handler(message: MyEvent):\n    \"\"\"Consumer for processing MyEvent(s)\"\"\"\n    # message.params.param\n    print(f\"Received Message {message.id} with data: {message.data}\")\n\n\n@service.subscribe()\nasync def example_run(message: MyCommand):\n    \"\"\"Consumer for processing MyCommands(s)\"\"\"\n    print(f\"Received Message {message.id} with data: {message.data}\")\n</code></pre> <p>Async API documentation generation</p> <pre><code>eventiq generate-docs examples.asyncapi:service --format=yaml --out=./asyncapi.yaml\n</code></pre>"},{"location":"examples/base/","title":"Basic","text":"examples/base.py<pre><code>import asyncio\nfrom typing import Any, Literal\n\nfrom pydantic import BaseModel\n\nfrom eventiq import CloudEvent, Middleware, Service\nfrom eventiq.backends.nats import JetStreamBroker\nfrom eventiq.middlewares.retries import RetryMiddleware\n\n\nclass TestParams(BaseModel):\n    action: Literal[\"create\", \"update\", \"delete\"]\n    region: str\n\n\nclass SomeEvent(CloudEvent[Any], topic=\"events.{region}.users.{action}\"):\n    some_attribute: str = \"some value\"\n\n\nclass SendMessageMiddleware(Middleware):\n    async def after_service_start(self, broker, service: Service):\n        print(f\"After service start, running with {broker}\")\n        await asyncio.sleep(5)\n        for i in range(100):\n            await service.send(\"test.topic\", data={\"counter\": i})\n\n        print(\"Published event(s)\")\n\n\nbroker = JetStreamBroker(\n    url=\"nats://localhost:4222\",\n    middlewares=[SendMessageMiddleware(), RetryMiddleware()],\n)\n\nservice = Service(name=\"example-service\", broker=broker)\n\n\n@service.subscribe(\"test.topic\")\nasync def example_run(message: CloudEvent):\n    print(f\"Received Message {message.id} with data: {message.data}\")\n    await asyncio.sleep(5)\n</code></pre> <p>Running example</p> <pre><code>eventiq examples.base:service\n</code></pre>"},{"location":"examples/generic_consumer/","title":"Generic Consumer","text":"examples/generic_consumer.py<pre><code>from eventiq import CloudEvent, GenericConsumer, Service\nfrom eventiq.backends.stub import StubBroker\n\nbroker = StubBroker()\n\nservice = Service(name=\"example-service\", broker=broker)\n\n\n@service.subscribe(\"example.topic\")\nclass MyConsumer(GenericConsumer[CloudEvent]):\n    # optionally replace `CloudEvent` with more specific class\n    name = \"example_consumer\"\n\n    async def process(self, message: CloudEvent):\n        print(message)\n</code></pre>"},{"location":"examples/prometheus/","title":"Prometheus","text":"examples/prometheus.py<pre><code>import asyncio\nimport logging\n\nfrom eventiq import CloudEvent, Middleware, Service\nfrom eventiq.backends.nats import JetStreamBroker\nfrom eventiq.middlewares import PrometheusMiddleware, RetryMiddleware\nfrom eventiq.middlewares.retries import MaxAge\n\nbroker = JetStreamBroker(url=\"nats://localhost:4222\")\nservice = Service(name=\"example-service\", broker=broker)\n\nlogger = logging.getLogger(\"consumer-logger\")\n\n\nclass SendMessageMiddleware(Middleware):\n    async def after_service_start(self, broker, service: Service):\n        self.logger.info(f\"After service start, running with {broker}\")\n        await asyncio.sleep(5)\n        for i in range(5):\n            await service.send(\"events.test.topic\", data={\"counter\": i})\n        self.logger.info(\"Published event(s)\")\n\n\nbroker.add_middlewares(\n    [SendMessageMiddleware(), RetryMiddleware(), PrometheusMiddleware(run_server=True)]\n)\n\n\n@service.subscribe(\n    \"events.test.topic\",\n    prefetch_count=100,\n    retry_strategy=MaxAge(max_age={\"seconds\": 60}),\n)\nasync def prometheus_consumer(message: CloudEvent):\n    logger.info(f\"Received Message {message.id} with data: {message.data}\")\n</code></pre> <p>Running example</p> <pre><code>eventiq run examples.prometheus:service --log-level=INFO\n</code></pre> <p>Then visit <code>http://localhost:8888</code> to see metrics exported</p>"},{"location":"examples/web/","title":"Fast API","text":"examples/web.py<pre><code>from typing import Any\n\nfrom fastapi import Body, FastAPI\nfrom fastapi.responses import JSONResponse, Response\n\nfrom eventiq import CloudEvent, Service\nfrom eventiq.asyncapi import PublishInfo\nfrom eventiq.backends.redis import RedisBroker, RedisResultBackend\nfrom eventiq.contrib.fastapi import FastAPIServicePlugin\nfrom eventiq.types import ID\n\nbroker: RedisBroker = RedisBroker(url=\"redis://localhost:6379/0\")\nresults = RedisResultBackend(broker)\n\nservice = Service(\n    name=\"example-service\",\n    broker=broker,\n    publish_info=[\n        PublishInfo.s(\n            CloudEvent,\n            topic=\"events.topic\",\n            description=\"Published on /publish endpoint\",\n        )\n    ],\n)\n\n\napp = FastAPI()\n\nFastAPIServicePlugin(service).configure_app(\n    app, healthcheck_url=\"/healthz\", async_api_url=\"/asyncapi\"\n)\n\n\n@service.subscribe(\"events.*\", name=\"test_consumer\", store_results=True)\nasync def handler(message: CloudEvent):\n    print(f\"Received Message {message.id} with data: {message.data}\")\n    return message.data\n\n\n@app.post(\"/publish\", status_code=202, response_model=CloudEvent)\nasync def publish_event(data: Any = Body(...)):\n    event: CloudEvent[Any] = CloudEvent(topic=\"events.nested.topic\", data=data)\n    await service.publish(event)\n    return event\n\n\n@app.get(\"/{message_id}\")\nasync def get_result(message_id: ID):\n    res: Any = await results.get_result(service.name, message_id)\n    if res is None:\n        return Response(status_code=404, content=\"Key not found\")\n    return JSONResponse(content=res)\n</code></pre> <p>Running example</p> <pre><code>uvicorn web:app\n</code></pre> <p>Note: FastAPI and uvicorn must be installed.</p>"},{"location":"reference/backends/","title":"Available Backends (Brokers)","text":""},{"location":"reference/backends/#base-broker","title":"Base Broker","text":""},{"location":"reference/backends/#eventiq.broker.Broker","title":"<code>eventiq.broker.Broker</code>","text":"<p>Base broker class</p> <p>Parameters:</p> Name Type Description Default <code>description</code> <code>str | None</code> <p>Broker (Server) Description</p> <code>None</code> <code>encoder</code> <code>Encoder | type[Encoder] | None</code> <p>Encoder (Serializer) class</p> <code>None</code> <code>middlewares</code> <code>list[Middleware] | None</code> <p>Optional list of middlewares</p> <code>None</code> Source code in <code>eventiq/broker.py</code> <pre><code>class Broker(AbstractBroker[RawMessage, R], LoggerMixin, ABC):\n    \"\"\"Base broker class\n    :param description: Broker (Server) Description\n    :param encoder: Encoder (Serializer) class\n    :param middlewares: Optional list of middlewares\n    \"\"\"\n\n    protocol: str\n    protocol_version: str = \"\"\n    message_proxy_class: type[Message[RawMessage]] = Message\n\n    Settings = BrokerSettings\n\n    WILDCARD_ONE: str\n    WILDCARD_MANY: str\n\n    def __init__(\n        self,\n        *,\n        description: str | None = None,\n        encoder: Encoder | type[Encoder] | None = None,\n        middlewares: list[Middleware] | None = None,\n        default_consumer_timeout: Timeout = 300,\n        default_on_exc: DefaultAction = \"nack\",\n        tags: list[str] | None = None,\n        asyncapi_extra: dict[str, Any] | None = None,\n        validate_error_delay: int = 3600 * 12,\n    ) -&gt; None:\n        if encoder is None:\n            from .encoders import get_default_encoder\n\n            encoder = get_default_encoder()\n        elif isinstance(encoder, type):\n            encoder = encoder()\n        self.encoder = encoder\n\n        self.description = description or type(self).__name__\n        self.middlewares: list[Middleware] = middlewares or []\n        self.default_consumer_timeout = to_float(default_consumer_timeout)\n        self.default_on_exc = default_on_exc\n        self.tags = tags\n        self.async_api_extra = asyncapi_extra or {}\n        self._lock = anyio.Lock()\n        self._connected = False\n        self.validate_error_delay = validate_error_delay\n\n    def __repr__(self):\n        return type(self).__name__\n\n    async def _handle_message_finalization(\n        self,\n        service: Service,\n        consumer: Consumer,\n        message: CloudEvent,\n        result: Any,\n        exc: Exception | CancelledError | None,\n    ):\n        self.logger.info(\n            f\"Finished running consumer {consumer.name} with message {message.id}\"\n        )\n        await self.dispatch_after(\n            \"process_message\", service, consumer, message, result, exc\n        )\n        if exc is None or message.failed:\n            await self.ack(service, consumer, message.raw)\n            return\n        if isinstance(exc, Fail):\n            self.logger.warning(f\"Failing message {message.id} due to {exc}\")\n            await self.ack(service, consumer, message.raw)\n            return\n        if isinstance(exc, Skip):\n            self.logger.info(f\"Skipping message {message.id} due to {exc}\")\n            await self.dispatch_after(\"skip_message\", service, consumer, message)\n            await self.ack(service, consumer, message.raw)\n            return\n        if isinstance(exc, Retry):\n            self.logger.info(\n                f\"Retrying message {message.id} in {exc.delay} due to {exc.reason}\"\n            )\n            await self.nack(service, consumer, message.raw)\n            return\n\n        if isinstance(exc, CancelledError):\n            self.logger.info(f\"Cancelled message {message.id} due to {exc}\")\n            await self.nack(service, consumer, message.raw)\n            return\n\n        await getattr(self, self.default_on_exc)(service, consumer, message.raw)\n\n    def _should_nack(self, message: RawMessage) -&gt; bool:\n        return False\n\n    def get_handler(\n        self, service: Service, consumer: Consumer\n    ) -&gt; Callable[..., Coroutine[Any, Any, Any]]:\n        consumer_timeout = to_float(consumer.timeout) or self.default_consumer_timeout\n        encoder = consumer.encoder or self.encoder\n\n        async def handler(raw_message: RawMessage) -&gt; None:\n            exc: Exception | CancelledError | None = None\n            result = None\n            msg = self.message_proxy_class(raw_message)\n            try:\n                parsed = self.parse_incoming_message(raw_message, encoder)\n                message = consumer.validate_message(parsed)\n                message.raw = msg\n                message.service = service\n            except (DecodeError, ValidationError) as e:\n                self.logger.error(\n                    f\"Failed to validate message {raw_message}.\", exc_info=e\n                )\n                if self._should_nack(raw_message):\n                    msg.delay = self.validate_error_delay\n                    await self.nack(service, consumer, msg)\n                else:\n                    await self.ack(service, consumer, msg)\n                return\n            try:\n                await self.dispatch_before(\n                    \"process_message\", service, consumer, message\n                )\n                self.logger.info(\n                    f\"Running consumer {consumer.name} with message {message.id}\"\n                )\n                with anyio.move_on_after(consumer_timeout) as scope:\n                    result = await consumer.process(message)\n                    if consumer.reply_to and result:\n                        for broker, spec in consumer.reply_to.items():\n                            ce = spec.type(topic=spec.topic, data=result)\n                            await service.publish(ce, broker=broker)\n                if scope.cancel_called:\n                    self.logger.warning(\n                        f\"Consumer {consumer.name} timed out on message {message.id}\"\n                    )\n                    exc = ConsumerTimeoutError()\n            except (CancelledError, Exception) as e:\n                exc = e\n            finally:\n                await self._handle_message_finalization(\n                    service, consumer, message, result, exc\n                )\n\n        return handler\n\n    async def ack(self, service: Service, consumer: Consumer, message: Message) -&gt; None:\n        await self.dispatch_before(\"ack\", service, consumer, message)\n        await self._ack(message)\n        await self.dispatch_after(\"ack\", service, consumer, message)\n\n    async def nack(\n        self,\n        service: Service,\n        consumer: Consumer,\n        message: Message,\n    ) -&gt; None:\n        await self.dispatch_after(\n            \"nack\",\n            service,\n            consumer,\n            message,\n        )\n        await self._nack(message)\n        await self.dispatch_after(\n            \"nack\",\n            service,\n            consumer,\n            message,\n        )\n\n    async def connect(self) -&gt; None:\n        async with self._lock:\n            if not self._connected:\n                await self.dispatch_before(\"broker_connect\")\n                await self._connect()\n                self._connected = True\n                await self.dispatch_after(\"broker_connect\")\n\n    async def disconnect(self) -&gt; None:\n        async with self._lock:\n            if self._connected:\n                await self.dispatch_before(\"broker_disconnect\")\n                self._connected = False\n                await self._disconnect()\n                await self.dispatch_after(\"broker_disconnect\")\n\n    async def publish(self, message: CloudEvent, **kwargs: Any) -&gt; R:\n        \"\"\"\n        :param message: Cloud event object to send\n        :param kwargs: Additional params passed to broker._publish\n        :rtype: None\n        \"\"\"\n        if not self.is_connected:\n            await self.connect()\n        await self.dispatch_before(\"publish\", message, **kwargs)\n        res = await self._publish(message, **kwargs)\n        await self.dispatch_after(\"publish\", message, **kwargs)\n        return res\n\n    async def start_consumer(self, service: Service, consumer: Consumer):\n        await self.dispatch_before(\"consumer_start\", service, consumer)\n        await self._start_consumer(service, consumer)\n        await self.dispatch_after(\"consumer_start\", service, consumer)\n\n    def add_middleware(self, middleware: Middleware | type[Middleware]) -&gt; None:\n        if isinstance(middleware, type):\n            middleware = middleware()\n        self.middlewares.append(middleware)\n\n    def add_middlewares(self, middlewares: list[Middleware | type[Middleware]]) -&gt; None:\n        for m in middlewares:\n            self.add_middleware(m)\n\n    async def _dispatch(self, full_event: str, *args, **kwargs) -&gt; None:\n        for middleware in self.middlewares:\n            try:\n                await getattr(middleware, full_event)(self, *args, **kwargs)\n            except middleware.throws as e:\n                self.logger.warning(\"Unhandled middleware exception\", exc_info=e)\n\n    async def dispatch_before(self, event: str, *args, **kwargs) -&gt; None:\n        await self._dispatch(f\"before_{event}\", *args, **kwargs)\n\n    async def dispatch_after(self, event: str, *args, **kwargs) -&gt; None:\n        await self._dispatch(f\"after_{event}\", *args, **kwargs)\n\n    @classmethod\n    def from_settings(cls, settings: BrokerSettings, **kwargs: Any) -&gt; Broker:\n        return cls(**settings.model_dump(), **kwargs)\n\n    @classmethod\n    def _from_env(cls, **kwargs) -&gt; Broker:\n        return cls.from_settings(cls.Settings(**kwargs))\n\n    @classmethod\n    def from_env(\n        cls,\n        **kwargs,\n    ) -&gt; Broker:\n        if cls == Broker:\n            type_name = os.getenv(\"BROKER_CLASS\", \"eventiq.backends.stub:StubBroker\")\n            broker_type = import_from_string(type_name)\n        else:\n            broker_type = cls\n        return broker_type._from_env(**kwargs)\n\n    @property\n    def safe_url(self) -&gt; str:\n        return \"\"\n\n    @staticmethod\n    def extra_message_span_attributes(message: RawMessage) -&gt; dict[str, Any]:\n        return {}\n\n    def format_topic(self, topic: str) -&gt; str:\n        return format_topic(topic, self.WILDCARD_ONE, self.WILDCARD_MANY)\n\n    async def _ack(self, message: Message) -&gt; None:\n        \"\"\"Empty default implementation for backends that do not support explicit ack\"\"\"\n\n    async def _nack(self, message: Message) -&gt; None:\n        \"\"\"Reject (requeue) message. Defaults to no-op like ._ack()\"\"\"\n</code></pre>"},{"location":"reference/backends/#eventiq.broker.Broker.publish","title":"<code>publish(message: CloudEvent, **kwargs: Any) -&gt; R</code>  <code>async</code>","text":"<p>Parameters:</p> Name Type Description Default <code>message</code> <code>CloudEvent</code> <p>Cloud event object to send</p> required <code>kwargs</code> <code>Any</code> <p>Additional params passed to broker._publish</p> <code>{}</code> Source code in <code>eventiq/broker.py</code> <pre><code>async def publish(self, message: CloudEvent, **kwargs: Any) -&gt; R:\n    \"\"\"\n    :param message: Cloud event object to send\n    :param kwargs: Additional params passed to broker._publish\n    :rtype: None\n    \"\"\"\n    if not self.is_connected:\n        await self.connect()\n    await self.dispatch_before(\"publish\", message, **kwargs)\n    res = await self._publish(message, **kwargs)\n    await self.dispatch_after(\"publish\", message, **kwargs)\n    return res\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.stub.StubBroker","title":"<code>eventiq.backends.stub.StubBroker</code>","text":"<p>This is in-memory implementation of a broker class, mainly designed for testing.</p> Source code in <code>eventiq/backends/stub.py</code> <pre><code>class StubBroker(Broker[StubMessage, dict[str, asyncio.Event]]):\n    \"\"\"This is in-memory implementation of a broker class, mainly designed for testing.\"\"\"\n\n    Settings = StubSettings\n\n    protocol = \"in-memory\"\n\n    WILDCARD_ONE = r\"\\w+\"\n    WILDCARD_MANY = \"*\"\n\n    def __init__(\n        self,\n        *,\n        encoder: Encoder | None = None,\n        middlewares: list[Middleware] | None = None,\n        wait_on_publish: bool = True,\n        **options: Any,\n    ) -&gt; None:\n        super().__init__(encoder=encoder, middlewares=middlewares, **options)\n        self.topics: dict[str, asyncio.Queue[StubMessage]] = defaultdict(\n            lambda: asyncio.Queue(maxsize=100)\n        )\n        self._stopped = False\n        self.wait_on_publish = wait_on_publish\n\n    def get_info(self) -&gt; ServerInfo:\n        return {\"host\": \"localhost\", \"protocol\": \"memory\"}\n\n    def parse_incoming_message(self, message: StubMessage, encoder: Encoder) -&gt; Any:\n        return encoder.decode(message.data)\n\n    async def _start_consumer(self, service: Service, consumer: Consumer):\n        queue = self.topics[self.format_topic(consumer.topic)]\n        handler = self.get_handler(service, consumer)\n        while self._connected:\n            message = await queue.get()\n            await handler(message)\n\n    async def _connect(self) -&gt; None:\n        pass\n\n    async def _disconnect(self) -&gt; None:\n        pass\n\n    async def _publish(self, message: CloudEvent, **kwargs) -&gt; dict[str, asyncio.Event]:\n        data = self.encoder.encode(message.model_dump())\n        headers = kwargs.get(\"headers\", {})\n        response = {}\n        for topic, queue in self.topics.items():\n            if re.fullmatch(topic, message.topic):\n                event = asyncio.Event()\n                msg = StubMessage(data=data, queue=queue, event=event, headers=headers)\n                await queue.put(msg)\n                response[topic] = event\n                if self.wait_on_publish:\n                    await event.wait()\n        return response\n\n    async def _ack(self, message: Message) -&gt; None:\n        message.queue.task_done()\n        message.event.set()\n\n    async def _nack(self, message: Message) -&gt; None:\n        await message.queue.put(message)\n\n    def is_connected(self) -&gt; bool:  # type: ignore[override]\n        return self._connected\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.nats.NatsBroker","title":"<code>eventiq.backends.nats.NatsBroker</code>","text":"Source code in <code>eventiq/backends/nats/broker.py</code> <pre><code>class NatsBroker(AbstractNatsBroker[NatsMsg, None]):\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        await self.client.subscribe(\n            subject=self.format_topic(consumer.topic),\n            queue=f\"{service.name}:{consumer.name}\",\n            cb=self.get_handler(service, consumer),\n        )\n\n    async def _publish(self, message: CloudEvent, **kwargs) -&gt; None:\n        data = self.encoder.encode(message.model_dump())\n        reply = kwargs.get(\"reply\", \"\")\n        headers = message.headers\n        headers.setdefault(\"Content-Type\", message.content_type)\n        await self.client.publish(message.topic, data, headers=headers, reply=reply)\n        if self._auto_flush or kwargs.get(\"flush\"):\n            await self.flush()\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.nats.JetStreamBroker","title":"<code>eventiq.backends.nats.JetStreamBroker</code>","text":"<p>NatsBroker with JetStream enabled</p> <p>Parameters:</p> Name Type Description Default <code>prefetch_count</code> <code>int</code> <p>default number of messages to prefetch</p> <code>10</code> <code>fetch_timeout</code> <code>int</code> <p>timeout for subscription pull</p> <code>10</code> <code>jetstream_options</code> <code>dict[str, Any] | None</code> <p>additional options passed to nc.jetstream(...)</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>all other options for base classes NatsBroker, Broker</p> <code>{}</code> Source code in <code>eventiq/backends/nats/broker.py</code> <pre><code>class JetStreamBroker(AbstractNatsBroker[NatsMsg, api.PubAck]):\n    \"\"\"\n    NatsBroker with JetStream enabled\n    :param prefetch_count: default number of messages to prefetch\n    :param fetch_timeout: timeout for subscription pull\n    :param jetstream_options: additional options passed to nc.jetstream(...)\n    :param kwargs: all other options for base classes NatsBroker, Broker\n    \"\"\"\n\n    Settings = JetStreamSettings\n\n    def __init__(\n        self,\n        *,\n        prefetch_count: int = 10,\n        fetch_timeout: int = 10,\n        jetstream_options: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.prefetch_count = prefetch_count\n        self.fetch_timeout = fetch_timeout\n        self.jetstream_options = jetstream_options or {}\n        self.js = JetStreamContext(self.client, **self.jetstream_options)\n\n    async def _publish(\n        self,\n        message: CloudEvent,\n        **kwargs,\n    ) -&gt; api.PubAck:\n        data = self.encoder.encode(message)\n        headers = message.headers\n        headers.setdefault(\"Content-Type\", message.content_type)\n        headers.setdefault(\"Nats-Msg-Id\", str(message.id))\n        try:\n            response = await self.js.publish(\n                subject=message.topic,\n                payload=data,\n                timeout=kwargs.get(\"timeout\"),\n                stream=kwargs.get(\"stream\"),\n                headers=headers,\n            )\n            if self._auto_flush:\n                await self.flush()\n            return response\n        except Exception as e:\n            raise PublishError from e\n\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        durable = f\"{service.name}:{consumer.name}\"\n        config = consumer.options.get(\"config\", ConsumerConfig())\n\n        if config.ack_wait is None:\n            ack_wait = (\n                to_float(consumer.timeout) or self.default_consumer_timeout\n            ) + 30\n            config.ack_wait = ack_wait  # consumer timeout + 30s for .ack()\n        try:\n            subscription = await self.js.pull_subscribe(\n                subject=self.format_topic(consumer.topic),\n                durable=durable,\n                config=config,\n            )\n        except Exception as e:\n            self.logger.warning(f\"Failed to create subscription: {e}\")\n            return\n\n        handler = self.get_handler(service, consumer)\n        batch = consumer.options.get(\"prefetch_count\", self.prefetch_count)\n        timeout = consumer.options.get(\"fetch_timeout\", self.fetch_timeout)\n        try:\n            while self._connected:\n                try:\n                    messages = await subscription.fetch(batch=batch, timeout=timeout)\n                    async with anyio.create_task_group() as tg:\n                        for i, msg in enumerate(messages):\n                            tg.start_soon(handler, msg, name=f\"{consumer.name}-{i}\")\n                    await self.flush()\n                except asyncio.TimeoutError:\n                    await anyio.sleep(5)\n                except Exception as e:\n                    self.logger.warning(f\"Cancelling consumer due to {e}\")\n                    return\n        finally:\n            if consumer.dynamic:\n                await subscription.unsubscribe()\n\n    def _should_nack(self, message: NatsMsg) -&gt; bool:\n        date = message.metadata.timestamp.replace(tzinfo=timezone.utc)\n        if date &lt; (utc_now() - timedelta(seconds=self.validate_error_delay)):\n            return True\n        return False\n\n    async def _ack(self, message: Message) -&gt; None:\n        if not message._ackd:\n            await message.ack()\n\n    async def _nack(self, message: Message) -&gt; None:\n        if not message._ackd:\n            await message.nak(delay=message.delay)\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.rabbitmq.RabbitmqBroker","title":"<code>eventiq.backends.rabbitmq.RabbitmqBroker</code>","text":"<p>RabbitMQ broker implementation, based on <code>aio_pika</code> library.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>rabbitmq connection string</p> required <code>default_prefetch_count</code> <code>int</code> <p>default number of messages to prefetch (per queue)</p> <code>10</code> <code>queue_options</code> <code>dict[str, Any] | None</code> <p>additional queue options</p> <code>None</code> <code>exchange_name</code> <code>str</code> <p>global exchange name</p> <code>'events'</code> <code>connection_options</code> <code>dict[str, Any] | None</code> <p>additional connection options passed to aio_pika.connect_robust</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Broker base class parameters</p> <code>{}</code> Source code in <code>eventiq/backends/rabbitmq/broker.py</code> <pre><code>class RabbitmqBroker(\n    Broker[aio_pika.abc.AbstractIncomingMessage, ConfirmationFrameType]\n):\n    \"\"\"\n    RabbitMQ broker implementation, based on `aio_pika` library.\n    :param url: rabbitmq connection string\n    :param default_prefetch_count: default number of messages to prefetch (per queue)\n    :param queue_options: additional queue options\n    :param exchange_name: global exchange name\n    :param connection_options: additional connection options passed to aio_pika.connect_robust\n    :param kwargs: Broker base class parameters\n    \"\"\"\n\n    Settings = RabbitMQSettings\n\n    WILDCARD_ONE = \"*\"\n    WILDCARD_MANY = \"#\"\n\n    def __init__(\n        self,\n        *,\n        url: str,\n        default_prefetch_count: int = 10,\n        queue_options: dict[str, Any] | None = None,\n        exchange_name: str = \"events\",\n        connection_options: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.url = url\n        self.default_prefetch_count = default_prefetch_count\n        self.queue_options = queue_options or {}\n        self.exchange_name = exchange_name\n        self.connection_options = connection_options or {}\n        self._connection = None\n        self._exchange = None\n        self._channels: list[aio_pika.abc.AbstractRobustChannel] = []\n\n    def get_info(self) -&gt; ServerInfo:\n        parsed = urlparse(self.url)\n        return {\n            \"host\": parsed.hostname,\n            \"protocol\": parsed.scheme,\n            \"pathname\": parsed.path,\n        }\n\n    @property\n    def safe_url(self) -&gt; str:\n        return get_safe_url(self.url)\n\n    @property\n    def connection(self) -&gt; aio_pika.RobustConnection:\n        if self._connection is None:\n            raise BrokerError(\"Not connected\")\n        return self._connection\n\n    @property\n    def exchange(self) -&gt; aio_pika.abc.AbstractRobustExchange:\n        return self._exchange\n\n    def _should_nack(self, message: aio_pika.abc.AbstractIncomingMessage) -&gt; bool:\n        return message.redelivered\n\n    async def _connect(self) -&gt; None:\n        self._connection = await aio_pika.connect_robust(\n            self.url, **self.connection_options\n        )\n        channel = await self.connection.channel()\n        self._exchange = await channel.declare_exchange(\n            name=self.exchange_name, type=aio_pika.ExchangeType.TOPIC, durable=True\n        )\n\n    async def _disconnect(self) -&gt; None:\n        for c in self._channels:\n            await c.close()\n        await self.connection.close()\n\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        \"\"\"\n        to route the messages to consumers\n        :param service:\n        :param consumer:\n        :return:\n        \"\"\"\n        channel = await self.connection.channel()\n        await channel.set_qos(\n            prefetch_count=consumer.options.get(\n                \"prefetch_count\", self.default_prefetch_count\n            )\n        )\n        options: dict[str, Any] = consumer.options.get(\n            \"queue_options\", self.queue_options\n        )\n        is_durable = not consumer.dynamic\n        options.setdefault(\"durable\", is_durable)\n        queue_name = f\"{service.name}:{consumer.name}\"\n        queue = await channel.declare_queue(name=queue_name, **options)\n        await queue.bind(self._exchange, routing_key=consumer.topic)\n        handler = self.get_handler(service, consumer)\n        await queue.consume(handler)\n        self._channels.append(channel)\n\n    async def _publish(self, message: CloudEvent, **kwargs) -&gt; None:\n        body = self.encoder.encode(\n            message.model_dump(\n                exclude={\n                    \"id\",\n                    \"type\",\n                    \"source\",\n                    \"content_type\",\n                    \"time\",\n                    \"topic\",\n                }\n            )\n        )\n        timeout = kwargs.get(\"timeout\")\n        headers = message.headers\n        headers.setdefault(\"Content-Type\", self.encoder.CONTENT_TYPE)\n        msg = aio_pika.Message(\n            headers=headers,\n            body=body,\n            app_id=message.source,\n            content_type=message.content_type,\n            timestamp=message.time,\n            message_id=str(message.id),\n            type=message.type,\n            content_encoding=\"UTF-8\",\n            delivery_mode=aio_pika.DeliveryMode.PERSISTENT,\n        )\n        return await self.exchange.publish(\n            msg, routing_key=message.topic, timeout=timeout\n        )\n\n    async def _ack(self, message: aio_pika.abc.AbstractIncomingMessage) -&gt; None:\n        await message.ack()\n\n    async def _nack(self, message: aio_pika.abc.AbstractIncomingMessage) -&gt; None:\n        await message.reject(requeue=True)\n\n    @property\n    def is_connected(self) -&gt; bool:\n        return not self.connection.is_closed\n\n    def parse_incoming_message(\n        self, message: aio_pika.abc.AbstractIncomingMessage, encoder: Encoder\n    ) -&gt; Any:\n        msg = encoder.decode(message.body)\n        if not isinstance(msg, dict):\n            raise TypeError(f\"Expected dict, got {type(msg)}\")\n        msg.update(\n            {\n                \"id\": message.message_id,\n                \"type\": message.type,\n                \"source\": message.app_id,\n                \"content_type\": message.content_type,\n                \"time\": message.timestamp,\n                \"topic\": message.routing_key,\n            }\n        )\n        return msg\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.kafka.KafkaBroker","title":"<code>eventiq.backends.kafka.KafkaBroker</code>","text":"<p>Kafka backend</p> <p>Parameters:</p> Name Type Description Default <code>bootstrap_servers</code> <code>str | list[str]</code> <p>url or list of kafka servers</p> required <code>publisher_options</code> <code>dict[str, Any] | None</code> <p>extra options for AIOKafkaProducer</p> <code>None</code> <code>consumer_options</code> <code>dict[str, Any] | None</code> <p>extra options (defaults) for AIOKafkaConsumer</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Broker base class parameters</p> <code>{}</code> Source code in <code>eventiq/backends/kafka/broker.py</code> <pre><code>class KafkaBroker(Broker[aiokafka.ConsumerRecord, None]):\n    \"\"\"\n    Kafka backend\n    :param bootstrap_servers: url or list of kafka servers\n    :param publisher_options: extra options for AIOKafkaProducer\n    :param consumer_options: extra options (defaults) for AIOKafkaConsumer\n    :param kwargs: Broker base class parameters\n    \"\"\"\n\n    WILDCARD_MANY = \"*\"\n    WILDCARD_ONE = r\"\\w+\"\n\n    Settings = KafkaSettings\n    protocol = \"kafka\"\n\n    def __init__(\n        self,\n        *,\n        bootstrap_servers: str | list[str],\n        publisher_options: dict[str, Any] | None = None,\n        consumer_options: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.bootstrap_servers = bootstrap_servers\n        self._publisher_options = publisher_options or {}\n        self._consumer_options = consumer_options or {}\n        self._publisher = None\n\n    def parse_incoming_message(\n        self, message: aiokafka.ConsumerRecord, encoder: Encoder\n    ) -&gt; Any:\n        return encoder.decode(message.value)\n\n    @property\n    def is_connected(self) -&gt; bool:\n        return True\n\n    def _should_nack(self, message: aiokafka.ConsumerRecord) -&gt; bool:\n        if (\n            message.timestamp\n            &lt; (utc_now() + timedelta(seconds=self.validate_error_delay)).timestamp()\n        ):\n            return True\n        return False\n\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        handler = self.get_handler(service, consumer)\n        subscriber = aiokafka.AIOKafkaConsumer(\n            group_id=f\"{service.name}:{consumer.name}\",\n            bootstrap_servers=self.bootstrap_servers,\n            enable_auto_commit=False,\n            **consumer.options.get(\"kafka_consumer_options\", self._consumer_options),\n        )\n        await subscriber.start()\n        subscriber.subscribe(pattern=self.format_topic(consumer.topic))\n        try:\n            while self._connected:\n                result = await subscriber.getmany(\n                    timeout_ms=consumer.options.get(\"timeout_ms\", 600)\n                )\n\n                for tp, messages in result.items():\n                    if messages:\n                        async with anyio.create_task_group() as tg:\n                            for message in messages:\n                                tg.start_soon(handler, message)\n                        await subscriber.commit({tp: messages[-1].offset + 1})\n        finally:\n            if consumer.dynamic:\n                subscriber.unsubscribe()\n\n    async def _disconnect(self):\n        if self._publisher:\n            await self._publisher.stop()\n\n    @property\n    def publisher(self) -&gt; aiokafka.AIOKafkaProducer:\n        if self._publisher is None:\n            raise BrokerError(\"Broker not connected\")\n        return self._publisher\n\n    async def _connect(self):\n        self._publisher = aiokafka.AIOKafkaProducer(\n            bootstrap_servers=self.bootstrap_servers, **self._publisher_options\n        )\n        await self._publisher.start()\n\n    async def _publish(\n        self,\n        message: CloudEvent,\n        key: Any | None = None,\n        partition: Any | None = None,\n        headers: dict[str, str] | None = None,\n        timestamp_ms: int | None = None,\n        **kwargs: Any,\n    ):\n        data = self.encoder.encode(message.model_dump())\n        timestamp_ms = timestamp_ms or int(message.time.timestamp() * 1000)\n        key = key or getattr(message, \"key\", str(message.id))\n        headers = headers or {}\n        headers.setdefault(\"Content-Type\", self.encoder.CONTENT_TYPE)\n        await self.publisher.send(\n            topic=message.topic,\n            value=data,\n            key=key,\n            partition=partition,\n            headers=headers,\n            timestamp_ms=timestamp_ms,\n        )\n\n    def get_info(self) -&gt; ServerInfo:\n        if isinstance(self.bootstrap_servers, str):\n            parsed = urlparse(self.bootstrap_servers)\n            return {\n                \"host\": parsed.hostname,\n                \"protocol\": parsed.scheme,\n                \"pathname\": parsed.path,\n            }\n        return {\n            \"host\": \",\".join(\n                urlparse(server).hostname or \"\" for server in self.bootstrap_servers\n            ),\n            \"protocol\": \"kafka\",\n            \"pathname\": \"\",\n        }\n\n    @property\n    def safe_url(self) -&gt; str:\n        if isinstance(self.bootstrap_servers, str):\n            return get_safe_url(self.bootstrap_servers)\n        return \",\".join(get_safe_url(server) for server in self.bootstrap_servers)\n\n    @staticmethod\n    def extra_message_span_attributes(\n        message: aiokafka.ConsumerRecord,\n    ) -&gt; dict[str, Any]:\n        return {\n            \"messaging.kafka.message.key\": message.key,\n            \"messaging.kafka.message.offset\": message.offset,\n            \"messaging.kafka.destination.partition\": message.partition,\n        }\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.redis.RedisBroker","title":"<code>eventiq.backends.redis.RedisBroker</code>","text":"<p>Broker implementation based on redis PUB/SUB and aioredis package</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>connection string to redis</p> required <code>connect_options</code> <code>dict[str, Any] | None</code> <p>additional connection options passed to aioredis.from_url</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>base class arguments</p> <code>{}</code> Source code in <code>eventiq/backends/redis/broker.py</code> <pre><code>class RedisBroker(Broker[RedisRawMessage, None]):\n    \"\"\"\n    Broker implementation based on redis PUB/SUB and aioredis package\n    :param url: connection string to redis\n    :param connect_options: additional connection options passed to aioredis.from_url\n    :param kwargs: base class arguments\n    \"\"\"\n\n    WILDCARD_ONE = \"*\"\n    WILDCARD_MANY = \"*\"\n    Settings = UrlBrokerSettings\n\n    def __init__(\n        self,\n        *,\n        url: str,\n        connect_options: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.url = url\n        self.connect_options = connect_options or {}\n        self._redis = None\n\n    @property\n    def safe_url(self) -&gt; str:\n        return get_safe_url(self.url)\n\n    def get_info(self) -&gt; ServerInfo:\n        parsed = urlparse(self.url)\n        return {\n            \"host\": parsed.hostname,\n            \"protocol\": parsed.scheme,\n            \"pathname\": parsed.path,\n        }\n\n    def parse_incoming_message(self, message: RedisRawMessage, encoder: Encoder) -&gt; Any:\n        return encoder.decode(message[\"data\"])\n\n    @property\n    def is_connected(self) -&gt; bool:\n        return self.redis.connection.is_connected\n\n    @property\n    def redis(self) -&gt; Redis:\n        if self._redis is None:\n            raise BrokerError(\"Not connected\")\n        return self._redis\n\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        handler = self.get_handler(service, consumer)\n        async with self.redis.pubsub() as sub:\n            await sub.psubscribe(consumer.topic)\n            while self._connected:\n                message = await sub.get_message(ignore_subscribe_messages=True)\n                if message:\n                    await handler(message)\n\n    async def _disconnect(self) -&gt; None:\n        await self.redis.aclose()\n\n    async def _connect(self) -&gt; None:\n        self._redis = Redis.from_url(self.url, **self.connect_options)\n\n    async def _publish(self, message: CloudEvent, **kwargs) -&gt; None:\n        data = self.encoder.encode(message)\n        await self.redis.publish(message.topic, data)\n</code></pre>"},{"location":"reference/backends/#eventiq.backends.pubsub.PubSubBroker","title":"<code>eventiq.backends.pubsub.PubSubBroker</code>","text":"<p>Google Cloud Pub/Sub broker implementation</p> <p>Parameters:</p> Name Type Description Default <code>service_file</code> <code>str</code> <p>path to the service account (json) file</p> required <code>kwargs</code> <code>Any</code> <p>Broker base class parameters</p> <code>{}</code> Source code in <code>eventiq/backends/pubsub/broker.py</code> <pre><code>class PubSubBroker(Broker[SubscriberMessage, dict[str, Any]]):\n    \"\"\"\n    Google Cloud Pub/Sub broker implementation\n    :param service_file: path to the service account (json) file\n    :param kwargs: Broker base class parameters\n    \"\"\"\n\n    Settings = PubSubSettings\n\n    WILDCARD_ONE = \"*\"\n    WILDCARD_MANY = \"*\"\n\n    message_proxy_class = PubSubMessageProxy\n\n    def __init__(\n        self,\n        *,\n        service_file: str,\n        **kwargs: Any,\n    ) -&gt; None:\n        super().__init__(**kwargs)\n        self.service_file = service_file\n        self._client = PublisherClient(service_file=self.service_file)\n\n    @property\n    def safe_url(self) -&gt; str:\n        return \"https://pubsub.googleapis.com/v1\"\n\n    def get_info(self) -&gt; ServerInfo:\n        return {\n            \"host\": \"pubsub.googleapis.com\",\n            \"protocol\": \"http\",\n            \"protocolVersion\": \"1.1\",\n            \"pathname\": \"/v1\",\n        }\n\n    def parse_incoming_message(\n        self, message: SubscriberMessage, encoder: Encoder\n    ) -&gt; Any:\n        return encoder.decode(message.data)\n\n    async def _start_consumer(self, service: Service, consumer: Consumer) -&gt; None:\n        consumer_client = SubscriberClient(service_file=self.service_file)\n        handler = self.get_handler(service, consumer)\n        await subscribe(\n            subscription=consumer.topic,\n            handler=handler,\n            subscriber_client=consumer_client,\n            **consumer.options.get(\"subscribe_options\", {}),\n        )\n\n    @property\n    def client(self) -&gt; PublisherClient:\n        return self._client\n\n    async def _publish(\n        self,\n        message: CloudEvent,\n        **kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        ordering_key = kwargs.get(\"ordering_key\", str(message.id))\n        timeout = kwargs.get(\"timeout\", 10)\n        msg = PubsubMessage(\n            data=self.encoder.encode(message.model_dump()),\n            ordering_key=ordering_key,\n            content_type=self.encoder.CONTENT_TYPE,\n            **message.headers,\n        )\n        return await self.client.publish(\n            topic=message.topic, messages=[msg], timeout=timeout\n        )\n\n    async def _connect(self) -&gt; None:\n        pass\n\n    async def _disconnect(self) -&gt; None:\n        await self.client.close()\n\n    @property\n    def is_connected(self) -&gt; bool:\n        return self.client.session._session.closed\n</code></pre>"},{"location":"reference/backends/#custom-broker","title":"Custom Broker","text":"<p>Create custom broker by subclassing <code>eventiq.broker.Broker</code> and implementing abstract methods.</p>"},{"location":"reference/consumers/","title":"Consumers","text":""},{"location":"reference/consumers/#reference","title":"Reference","text":""},{"location":"reference/consumers/#eventiq.consumer.Consumer","title":"<code>eventiq.consumer.Consumer</code>","text":"<p>             Bases: <code>ABC</code>, <code>Generic[CE]</code></p> <p>Base consumer class</p> Source code in <code>eventiq/consumer.py</code> <pre><code>class Consumer(ABC, Generic[CE]):\n    \"\"\"Base consumer class\"\"\"\n\n    event_type: CE\n\n    def __init__(\n        self,\n        *,\n        name: str,\n        topic: str | None = None,\n        brokers: tuple[str] = (\"default\",),\n        timeout: Timeout | None = None,\n        dynamic: bool = False,\n        reply_to: ReplyTo | None = None,\n        tags: Tags = None,\n        retry_strategy: RetryStrategy | None = None,\n        store_results: bool = False,\n        encoder: Encoder | None = None,\n        parameters: dict[str, Any] | None = None,\n        **options: Any,\n    ):\n        topic = topic or self.event_type.get_default_topic()\n        if not topic:\n            raise ValueError(\"Topic expected\")\n        self.name = name\n        self.brokers = brokers\n        self.topic = topic\n        self.timeout = timeout\n        self.dynamic = dynamic\n        self.reply_to = reply_to\n        self.tags = tags or []\n        self.retry_strategy = retry_strategy\n        self.store_results = store_results\n        self.encoder = encoder\n        self.parameters = parameters or {}\n        self.options: dict[str, Any] = options\n        self.logger = get_logger(__name__, self.name)\n\n    def validate_message(self, message: Any) -&gt; CloudEvent:\n        return self.event_type.model_validate(message)\n\n    @property\n    @abstractmethod\n    def description(self) -&gt; str:\n        raise NotImplementedError\n\n    @abstractmethod\n    async def process(self, message: CE) -&gt; Any:\n        raise NotImplementedError\n</code></pre>"},{"location":"reference/consumers/#eventiq.consumer.FnConsumer","title":"<code>eventiq.consumer.FnConsumer</code>","text":"<p>             Bases: <code>Consumer[CE]</code></p> Source code in <code>eventiq/consumer.py</code> <pre><code>class FnConsumer(Consumer[CE]):\n    def __init__(\n        self,\n        *,\n        fn: FT,\n        **extra: Any,\n    ) -&gt; None:\n        event_type = resolve_message_type_hint(fn)\n        if not event_type:\n            raise TypeError(\n                \"Unable to resolve type hint for 'message' in %s\", fn.__name__\n            )\n        self.event_type = event_type\n        if not asyncio.iscoroutinefunction(fn):\n            fn = to_async(fn)\n        self.fn = fn\n        super().__init__(**extra)\n\n    async def process(self, message: CE) -&gt; Any:\n        return await self.fn(message)\n\n    @property\n    def description(self) -&gt; str:\n        return self.fn.__doc__ or \"\"\n</code></pre>"},{"location":"reference/consumers/#eventiq.consumer.GenericConsumer","title":"<code>eventiq.consumer.GenericConsumer</code>","text":"<p>             Bases: <code>Consumer[CE]</code>, <code>ABC</code></p> Source code in <code>eventiq/consumer.py</code> <pre><code>class GenericConsumer(Consumer[CE], ABC):\n    def __init_subclass__(cls, **kwargs):\n        if not inspect.isabstract(cls):\n            cls.event_type = cls.__orig_bases__[0].__args__[0]\n            if not asyncio.iscoroutinefunction(cls.process):\n                cls.process = to_async(cls.process)\n\n    @property\n    def description(self) -&gt; str:\n        return self.__doc__ or \"\"\n</code></pre>"},{"location":"reference/encoders/","title":"Encoders","text":""},{"location":"reference/encoders/#encoders","title":"Encoders","text":""},{"location":"reference/encoders/#eventiq.encoder.Encoder","title":"<code>eventiq.encoder.Encoder</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Encoder object protocol.</p>"},{"location":"reference/encoders/#eventiq.encoder.Encoder.CONTENT_TYPE","title":"<code>CONTENT_TYPE: str</code>  <code>instance-attribute</code>","text":""},{"location":"reference/encoders/#eventiq.encoder.Encoder.encode","title":"<code>encode(data: Any) -&gt; bytes</code>  <code>abstractmethod</code>","text":"<p>Serialize object to bytes</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>input value, usually CloudEvent.model_dump()</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>raw content as bytes</p>"},{"location":"reference/encoders/#eventiq.encoder.Encoder.decode","title":"<code>decode(data: bytes) -&gt; Any</code>  <code>abstractmethod</code>","text":"<p>Deserialize bytes to python object</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>bytes</code> <p>input bytes</p> required <p>Returns:</p> Type Description <code>Any</code> <p>de-serialized object</p>"},{"location":"reference/encoders/#eventiq.encoders.json.JsonEncoder","title":"<code>eventiq.encoders.json.JsonEncoder</code>","text":"<p>             Bases: <code>Encoder</code></p> <p>Default encoder, serializes CloudEvent models to json objects.</p> Source code in <code>eventiq/encoders/json.py</code> <pre><code>class JsonEncoder(Encoder):\n    \"\"\"\n    Default encoder, serializes CloudEvent models to json objects.\n    \"\"\"\n\n    CONTENT_TYPE = \"application/json\"\n\n    def encode(self, data: Any) -&gt; bytes:\n        try:\n            return json.dumps(data, default=to_jsonable_python).encode(\"utf-8\")\n        except TypeError as e:\n            raise EncodeError from e\n\n    def decode(self, data: bytes) -&gt; Any:\n        try:\n            return json.loads(data)\n        except json.JSONDecodeError as e:\n            raise DecodeError from e\n</code></pre>"},{"location":"reference/encoders/#eventiq.encoders.orjson.OrjsonEncoder","title":"<code>eventiq.encoders.orjson.OrjsonEncoder</code>","text":"<p>             Bases: <code>Encoder</code></p> <p>Json encoder which utilizes orjson library.</p> Source code in <code>eventiq/encoders/orjson.py</code> <pre><code>class OrjsonEncoder(Encoder):\n    \"\"\"\n    Json encoder which utilizes orjson library.\n    \"\"\"\n\n    CONTENT_TYPE = \"application/json\"\n\n    def encode(self, data: Any) -&gt; bytes:\n        try:\n            return orjson.dumps(\n                data,\n                option=orjson.OPT_NON_STR_KEYS | orjson.OPT_SERIALIZE_NUMPY,\n                default=to_jsonable_python,\n            )\n        except TypeError as e:\n            raise EncodeError from e\n\n    def decode(self, data: bytes) -&gt; Any:\n        try:\n            return orjson.loads(data)\n        except orjson.JSONDecodeError as e:\n            raise DecodeError from e\n</code></pre>"},{"location":"reference/encoders/#eventiq.encoders.msgpack.MsgPackEncoder","title":"<code>eventiq.encoders.msgpack.MsgPackEncoder</code>","text":"<p>             Bases: <code>Encoder</code></p> <p>Message Pack encoder implementation using <code>ormsgpack</code> library.</p> Source code in <code>eventiq/encoders/msgpack.py</code> <pre><code>class MsgPackEncoder(Encoder):\n    \"\"\"\n    Message Pack encoder implementation using `ormsgpack` library.\n    \"\"\"\n\n    CONTENT_TYPE = \"application/x-msgpack\"\n\n    def encode(self, data: Any) -&gt; bytes:\n        try:\n            return ormsgpack.packb(\n                data,\n                option=ormsgpack.OPT_NON_STR_KEYS | ormsgpack.OPT_SERIALIZE_NUMPY,\n                default=to_jsonable_python,\n            )\n        except ormsgpack.MsgpackEncodeError as e:\n            raise EncodeError from e\n\n    def decode(self, data: bytes) -&gt; Any:\n        try:\n            return ormsgpack.unpackb(data)\n        except ormsgpack.MsgpackDecodeError as e:\n            raise DecodeError from e\n</code></pre>"},{"location":"reference/encoders/#eventiq.encoders.pickle.PickleEncoder","title":"<code>eventiq.encoders.pickle.PickleEncoder</code>","text":"<p>             Bases: <code>Encoder</code></p> <p>Pickle encoder implementation. Allows to pass/serialize python native objects, but it is not recommended. See warning: https://docs.python.org/3/library/pickle.html</p> Source code in <code>eventiq/encoders/pickle.py</code> <pre><code>class PickleEncoder(Encoder):\n    \"\"\"\n    Pickle encoder implementation. Allows to pass/serialize python native objects,\n    but it is not recommended. See warning: &lt;https://docs.python.org/3/library/pickle.html&gt;\n    \"\"\"\n\n    CONTENT_TYPE = \"application/octet-stream\"\n\n    def encode(self, data: Any) -&gt; bytes:\n        try:\n            return pickle.dumps(data)\n        except Exception as e:\n            raise EncodeError from e\n\n    def decode(self, data: bytes) -&gt; Any:\n        try:\n            return pickle.loads(data)  # nosec\n        except (pickle.UnpicklingError, TypeError) as e:\n            raise DecodeError from e\n</code></pre>"},{"location":"reference/exceptions/","title":"Exceptions","text":""},{"location":"reference/exceptions/#eventiq.exceptions.ConfigurationError","title":"<code>eventiq.exceptions.ConfigurationError</code>","text":"<p>             Bases: <code>EventiqError</code></p> <p>Raised by framework when invalid configuration is supplied</p>"},{"location":"reference/exceptions/#eventiq.exceptions.Skip","title":"<code>eventiq.exceptions.Skip</code>","text":"<p>             Bases: <code>MessageError</code></p> <p>Raise exception to skip message without processing and/or retrying</p>"},{"location":"reference/exceptions/#eventiq.exceptions.Fail","title":"<code>eventiq.exceptions.Fail</code>","text":"<p>             Bases: <code>MessageError</code></p> <p>Fail message without retrying</p>"},{"location":"reference/exceptions/#eventiq.exceptions.Retry","title":"<code>eventiq.exceptions.Retry</code>","text":"<p>             Bases: <code>MessageError</code></p> <p>Utility exception for retrying message. RetryMiddleware must be added</p>"},{"location":"reference/middlewares/","title":"Middlewares","text":"<p>List of built-in middlewares</p>"},{"location":"reference/middlewares/#eventiq.middlewares.debug.DebugMiddleware","title":"<code>eventiq.middlewares.debug.DebugMiddleware</code>","text":"<p>             Bases: <code>Middleware</code></p> <p>Log every event</p> Source code in <code>eventiq/middlewares/debug.py</code> <pre><code>class DebugMiddleware(Middleware, metaclass=DebugMeta):\n    \"\"\"Log every event\"\"\"\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.error.ErrorHandlerMiddleware","title":"<code>eventiq.middlewares.error.ErrorHandlerMiddleware</code>","text":"<p>             Bases: <code>Middleware</code></p> Source code in <code>eventiq/middlewares/error.py</code> <pre><code>class ErrorHandlerMiddleware(Middleware):\n    def __init__(self, errors: type[Exception] | tuple[type[Exception]], callback):\n        if not asyncio.iscoroutinefunction(callback):\n            callback = to_async(callback)\n        self.callback = callback\n        self.exc = errors\n\n    async def after_process_message(\n        self,\n        broker: Broker,\n        service: Service,\n        consumer: Consumer,\n        message: CloudEvent,\n        result: Any | None = None,\n        exc: Exception | None = None,\n    ):\n        if exc and isinstance(exc, self.exc):\n            await self.callback(message, exc)\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.healthcheck.HealthCheckMiddleware","title":"<code>eventiq.middlewares.healthcheck.HealthCheckMiddleware</code>","text":"<p>             Bases: <code>BackGroundTasksMiddleware</code></p> <p>Middleware for performing basic health checks on broker</p> Source code in <code>eventiq/middlewares/healthcheck.py</code> <pre><code>class HealthCheckMiddleware(BackGroundTasksMiddleware):\n    \"\"\"Middleware for performing basic health checks on broker\"\"\"\n\n    BASE_DIR = os.getenv(\"HEALTHCHECK_DIR\", \"/tmp\")  # nosec\n\n    def __init__(\n        self,\n        interval: int = 30,\n        predicates: list[Callable[..., Awaitable[Any]]] | None = None,\n    ):\n        super().__init__()\n        self.interval = interval\n        self.predicates = predicates\n\n    async def after_broker_connect(self, broker: T):\n        await super().after_broker_connect(broker)\n        self.submit(self._run_forever, broker)\n\n    async def _run_forever(self, broker: T) -&gt; None:\n        p = Path(os.path.join(self.BASE_DIR, \"healthy\"))\n        p.touch(exist_ok=True)\n        while True:\n            try:\n                unhealthy = not broker.is_connected\n\n                if self.predicates:\n                    with anyio.move_on_after(10) as scope:\n                        async with anyio.create_task_group() as tg:\n                            for f in self.predicates:\n                                tg.start_soon(f)\n                    if scope.cancel_called:\n                        self.logger.warning(\"Healthcheck predicate timed out\")\n                        unhealthy = True\n            except anyio.get_cancelled_exc_class():\n                return\n            except Exception as e:\n                self.logger.exception(\"Healthcheck failed\", exc_info=e)\n                unhealthy = True\n\n            if unhealthy:\n                p.rename(os.path.join(self.BASE_DIR, \"unhealthy\"))\n                break\n            await anyio.sleep(self.interval)\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.prometheus.PrometheusMiddleware","title":"<code>eventiq.middlewares.prometheus.PrometheusMiddleware</code>","text":"<p>             Bases: <code>Middleware</code></p> Source code in <code>eventiq/middlewares/prometheus.py</code> <pre><code>class PrometheusMiddleware(Middleware):\n    def __init__(\n        self,\n        run_server: bool = False,\n        registry: CollectorRegistry | None = None,\n        buckets: tuple[float] | None = None,\n        server_host: str = \"0.0.0.0\",  # nosec\n        server_port: int = 8888,\n        prefix: str = \"\",\n        **http_server_options: Any,\n    ):\n        from prometheus_client import REGISTRY, Counter, Gauge, Histogram\n\n        self.run_server = run_server\n        self.registry = registry or REGISTRY\n        self.buckets = buckets or DEFAULT_BUCKETS\n        self.server_host = server_host\n        self.server_port = server_port\n        self.message_start_times: dict[tuple[str, str, ID], int] = {}\n        self.prefix = prefix\n        self.http_server_options = http_server_options\n        self.in_progress = Gauge(\n            self.format(\"messages_in_progress\"),\n            \"Total number of messages being processed.\",\n            [\"topic\", \"service\", \"consumer\"],\n            registry=self.registry,\n        )\n        self.total_messages = Counter(\n            self.format(\"messages_total\"),\n            \"Total number of messages processed.\",\n            [\"topic\", \"service\", \"consumer\"],\n            registry=self.registry,\n        )\n        self.total_skipped_messages = Counter(\n            self.format(\"messages_skipped_total\"),\n            \"Total number of messages skipped processing.\",\n            registry=self.registry,\n        )\n        self.total_messages_published = Counter(\n            self.format(\"messages_published_total\"),\n            \"Total number of messages published\",\n            [\"topic\", \"service\"],\n            registry=self.registry,\n        )\n        self.total_errored_messages = Counter(\n            self.format(\"message_error_total\"),\n            \"Total number of errored messages.\",\n            [\"topic\", \"service\", \"consumer\"],\n            registry=self.registry,\n        )\n        self.total_failed_messages = Counter(\n            self.format(\"message_failed_total\"),\n            \"Total number of messages failed\",\n            [\"topic\", \"service\", \"consumer\"],\n            registry=self.registry,\n        )\n        self.message_durations = Histogram(\n            self.format(\"message_duration_ms\"),\n            \"Time spend processing message\",\n            [\"topic\", \"service\", \"consumer\"],\n            registry=self.registry,\n            buckets=self.buckets,\n        )\n\n    def format(self, value: str) -&gt; str:\n        if self.prefix:\n            return f\"{self.prefix}_{value}\"\n        return value\n\n    async def before_process_message(\n        self, broker: Broker, service: Service, consumer: Consumer, message: CloudEvent\n    ):\n        labels = (consumer.topic, service.name, consumer.name)\n        self.in_progress.labels(*labels).inc()\n        self.message_start_times[\n            (service.name, consumer.name, message.id)\n        ] = current_millis()\n\n    async def after_process_message(\n        self,\n        broker: Broker,\n        service: Service,\n        consumer: Consumer,\n        message: CloudEvent,\n        result: Any | None = None,\n        exc: Exception | None = None,\n    ) -&gt; None:\n        labels = (consumer.topic, service.name, consumer.name)\n        self.in_progress.labels(*labels).dec()\n        self.total_messages.labels(*labels).inc()\n        if exc:\n            self.total_errored_messages.labels(*labels).inc()\n\n        message_start_time = self.message_start_times.pop(\n            (service.name, consumer.name, message.id), current_millis()\n        )\n        message_duration = current_millis() - message_start_time\n        self.message_durations.labels(*labels).observe(message_duration)\n\n    async def after_skip_message(\n        self, broker: Broker, service: Service, consumer: Consumer, message: CloudEvent\n    ) -&gt; None:\n        labels = (consumer.topic, service.name, consumer.name)\n        self.total_skipped_messages.labels(*labels).inc()\n\n    async def after_publish(self, broker: Broker, message: CloudEvent, **kwargs):\n        self.total_messages_published.labels(message.topic, message.source).inc()\n\n    async def after_nack(\n        self, broker: Broker, service: Service, consumer: Consumer, message: Message\n    ):\n        labels = (consumer.topic, service.name, consumer.name)\n        self.total_errored_messages.labels(*labels).inc()\n\n    async def after_ack(\n        self,\n        broker: Broker,\n        service: Service,\n        consumer: Consumer,\n        message: Message,\n    ) -&gt; None:\n        if message.failed:\n            labels = (consumer.topic, service.name, consumer.name)\n            self.total_failed_messages.labels(*labels).inc()\n\n    async def after_broker_connect(self, broker: Broker):\n        if self.run_server:\n            from prometheus_client import start_http_server\n\n            start_http_server(\n                self.server_port,\n                self.server_host,\n                registry=self.registry,\n                **self.http_server_options,\n            )\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.retries.RetryMiddleware","title":"<code>eventiq.middlewares.retries.RetryMiddleware</code>","text":"<p>             Bases: <code>Middleware</code></p> <p>Retry Message Middleware. Supported retry strategies: - <code>MaxAge</code> (default) - retry with exponential backoff up to max_age - <code>MaxRetries</code> - retry up to N times (currently supported only by nats) - <code>RetryWhen</code> - provide custom callable to determine weather message should be retried</p> Source code in <code>eventiq/middlewares/retries.py</code> <pre><code>class RetryMiddleware(Middleware):\n    \"\"\"\n    Retry Message Middleware.\n    Supported retry strategies:\n    - `MaxAge` (default) - retry with exponential backoff up to max_age\n    - `MaxRetries` - retry up to N times (currently supported only by nats)\n    - `RetryWhen` - provide custom callable to determine weather message should be retried\n    \"\"\"\n\n    def __init__(\n        self,\n        delay_header: str = \"x-delay\",\n        default_retry_strategy: RetryStrategy | None = None,\n    ):\n        self.delay_header = delay_header\n        self.default_retry_strategy = default_retry_strategy or MaxAge(\n            max_age=timedelta(hours=1)\n        )\n\n    async def after_process_message(\n        self,\n        broker: Broker,\n        service: Service,\n        consumer: Consumer,\n        message: CloudEvent,\n        result: Any | None = None,\n        exc: Exception | None = None,\n    ):\n        if exc is None:\n            return\n\n        if isinstance(exc, Retry):\n            message.raw.delay = exc.delay\n            return\n\n        retry_strategy = consumer.retry_strategy or self.default_retry_strategy\n        if retry_strategy is None:\n            return\n\n        retry_strategy.maybe_retry(message, exc)\n\n    async def before_publish(self, broker: T, message: CloudEvent, **kwargs) -&gt; None:\n        delay = kwargs.get(\"delay\", message.delay)\n\n        if delay is not None and self.delay_header:\n            message.set_header(self.delay_header, str(delay))\n\n    async def before_process_message(\n        self, broker: T, service: Service, consumer: Consumer, message: CloudEvent\n    ) -&gt; None:\n        \"\"\"Broker agnostic implementation of not-before header.\"\"\"\n        if self.delay_header:\n            delay_header = int(message.headers.get(self.delay_header, 0))\n            if delay_header and message.age &lt; timedelta(seconds=delay_header):\n                raise Retry(f\"Delay header set to {delay_header}\", delay=delay_header)\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.retries.RetryMiddleware.before_process_message","title":"<code>before_process_message(broker: T, service: Service, consumer: Consumer, message: CloudEvent) -&gt; None</code>  <code>async</code>","text":"<p>Broker agnostic implementation of not-before header.</p> Source code in <code>eventiq/middlewares/retries.py</code> <pre><code>async def before_process_message(\n    self, broker: T, service: Service, consumer: Consumer, message: CloudEvent\n) -&gt; None:\n    \"\"\"Broker agnostic implementation of not-before header.\"\"\"\n    if self.delay_header:\n        delay_header = int(message.headers.get(self.delay_header, 0))\n        if delay_header and message.age &lt; timedelta(seconds=delay_header):\n            raise Retry(f\"Delay header set to {delay_header}\", delay=delay_header)\n</code></pre>"},{"location":"reference/middlewares/#eventiq.middlewares.opentelemetry.OpenTelemetryMiddleware","title":"<code>eventiq.middlewares.opentelemetry.OpenTelemetryMiddleware</code>","text":"<p>             Bases: <code>Middleware</code></p> Source code in <code>eventiq/middlewares/opentelemetry.py</code> <pre><code>class OpenTelemetryMiddleware(Middleware):\n    def __init__(\n        self, provider: TracerProvider | None = None, record_exceptions: bool = True\n    ):\n        if provider is None:\n            provider = trace.get_tracer_provider()\n        self.record_exceptions = record_exceptions\n        self.tracer = provider.get_tracer(\"eventiq\", __version__)\n        self.process_span_registry: dict[\n            tuple[str, str, ID], tuple[Span, ContextManager[Span]]\n        ] = {}\n        self.publish_span_registry: dict[ID, tuple[Span, ContextManager[Span]]] = {}\n\n    @staticmethod\n    def _get_span_attributes(message: CloudEvent, broker: Broker | None = None):\n        extra = broker.extra_message_span_attributes(message.raw) if broker else {}\n        return {\n            SpanAttributes.CLOUDEVENTS_EVENT_ID: str(message.id),\n            SpanAttributes.CLOUDEVENTS_EVENT_SOURCE: message.source or \"(anonymous)\",\n            SpanAttributes.CLOUDEVENTS_EVENT_TYPE: message.type or \"CloudEvent\",\n            SpanAttributes.CLOUDEVENTS_EVENT_SUBJECT: message.topic,\n            **{\n                k: str(v)\n                for k, v in chain(extra.items(), message.extra_span_attributes.items())\n                if v is not None\n            },\n        }\n\n    async def before_process_message(\n        self, broker: Broker, service: Service, consumer: Consumer, message: CloudEvent\n    ) -&gt; None:\n        trace_ctx = extract(message, getter=eventiq_getter)\n\n        span = self.tracer.start_span(\n            name=f\"{consumer.name} receive\",\n            kind=SpanKind.CONSUMER,\n            context=trace_ctx,\n            attributes=self._get_span_attributes(message, broker),\n        )\n        activation = trace.use_span(span, end_on_exit=True)\n        activation.__enter__()\n        self.process_span_registry[(service.name, consumer.name, message.id)] = (\n            span,\n            activation,\n        )\n\n    async def after_process_message(\n        self,\n        broker: Broker,\n        service: Service,\n        consumer: Consumer,\n        message: CloudEvent,\n        result: Any | None = None,\n        exc: Exception | None = None,\n    ) -&gt; None:\n        key = (service.name, consumer.name, message.id)\n        span, activation = self.process_span_registry.pop(key, (None, None))\n        if span is None or activation is None:\n            self.logger.warning(\"No active span was found\")\n            return\n\n        if span.is_recording():\n            if exc:\n                if isinstance(exc, (Retry, Skip)):\n                    span.set_status(StatusCode.OK, description=str(exc))\n                else:\n                    if self.record_exceptions:\n                        span.record_exception(exc)\n                    span.set_status(StatusCode.ERROR, description=str(exc))\n\n            else:\n                if message.failed:\n                    span.set_status(StatusCode.ERROR, description=\"Failed\")\n                else:\n                    span.set_status(StatusCode.OK)\n\n        activation.__exit__(None, None, None)\n\n    async def before_publish(\n        self, broker: Broker, message: CloudEvent, **kwargs\n    ) -&gt; None:\n        source = message.source or \"(anonymous)\"\n\n        span = self.tracer.start_span(\n            f\"{source} publish\",\n            kind=SpanKind.PRODUCER,\n            attributes=self._get_span_attributes(message),\n        )\n        activation = trace.use_span(span, end_on_exit=True)\n        activation.__enter__()\n        self.publish_span_registry[message.id] = (span, activation)\n        inject(message, setter=eventiq_setter)\n\n    async def after_publish(\n        self, broker: Broker, message: CloudEvent, **kwargs\n    ) -&gt; None:\n        span, activation = self.publish_span_registry.pop(message.id, (None, None))\n        if span and span.is_recording():\n            span.set_status(StatusCode.OK)\n        if activation is not None:\n            activation.__exit__(None, None, None)\n</code></pre>"}]}